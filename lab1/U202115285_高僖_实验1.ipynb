{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26f660c",
   "metadata": {},
   "source": [
    "# 上机实验1：基于前馈神经网络的分类任务设计\n",
    "计卓2101 高僖 U202115285\n",
    "## 网络设计：\n",
    "设计了隐藏层尺寸分别为[32,16]，[64,32,16]，[128,64,32,16] 三种前馈神经网络，激活函数分别选择Relu，cos和sigmoid三种函数进行实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89d732",
   "metadata": {},
   "source": [
    "## 其他训练参数\n",
    "\n",
    "使用Adam优化器（参数为tensorflow默认设置），交叉熵作为损失函数；batch size设为32；epoch数为10。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b033bf58",
   "metadata": {},
   "source": [
    "## 实验结果与分析\n",
    "### 不同隐藏层的对比实验\n",
    "\n",
    "实验中激活函数均为Relu\n",
    "\n",
    "隐藏层为[32,16]\n",
    "<img src=\"(32, 16)_neuron_configuration_training_plot.png\" style=\"zoom:100%;\" />\n",
    "每一轮mini-batch训练后的模型在训练集和测试集上的损失见附录代码运行结果 <br/>\n",
    "最终训练集准确度为0.9237654209136963 <br/>\n",
    "测试集准确度为0.9275000095367432\n",
    "\n",
    "\n",
    "隐藏层为[64,32,16]\n",
    "<img src=\"(64, 32, 16)_neuron_configuration_training_plot.png\" style=\"zoom:100%;\" />\n",
    "每一轮mini-batch训练后的模型在训练集和测试集上的损失见附录代码运行结果 <br/>\n",
    "最终训练集准确度为0.9228395223617554 <br/>\n",
    "测试集准确度为0.9300000071525574\n",
    "\n",
    "\n",
    "隐藏层为[128,64,32,16] \n",
    "<img src=\"(128, 64, 32, 16)_neuron_configuration_training_plot.png\" style=\"zoom:100%;\" />\n",
    "每一轮mini-batch训练后的模型在训练集和测试集上的损失见附录代码运行结果 <br/>\n",
    "最终训练集准确度为0.9259259104728699 <br/>\n",
    "测试集准确度为0.925000011920929\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36ffea",
   "metadata": {},
   "source": [
    "#### 分析\n",
    "\n",
    "可以看到，对于简单的拟合任务，网络基本不存在过拟合现象，在同样的训练参数设置下，更复杂的神经网络在有限的训练iteration下拟合函数的能力更强。\n",
    "但是准确率差不多，甚至出现了更复杂的神经网络准确率有所下降的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf3624",
   "metadata": {},
   "source": [
    "### 不同激活函数的对比实验\n",
    "\n",
    "实验中网络隐藏层尺寸均为[64, 32]\n",
    "\n",
    "使用Relu激活函数：\n",
    "<img src=\"relu_training_plot.png\" style=\"zoom:100%;\" />\n",
    "每一轮mini-batch训练后的模型在训练集和测试集上的损失见附录代码运行结果 <br/>\n",
    "最终训练集准确度为0.9209876656532288 <br/>\n",
    "测试集准确度为0.9024999737739563\n",
    "\n",
    "使用Sigmoid激活函数：\n",
    "<img src=\"sigmoid_training_plot.png\" style=\"zoom:100%;\" />\n",
    "每一轮mini-batch训练后的模型在训练集和测试集上的损失见附录代码运行结果 <br/>\n",
    "最终训练集准确度为0.9138888716697693 <br/>\n",
    "测试集准确度为0.8999999761581421\n",
    "\n",
    "使用Tanh激活函数：\n",
    "<img src=\"Tanh_training_plot.png\" style=\"zoom:100%;\" />\n",
    "每一轮mini-batch训练后的模型在训练集和测试集上的损失见附录代码运行结果 <br/>\n",
    "最终训练集准确度为0.9268518686294556 <br/>\n",
    "测试集准确度为0.9075000286102295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24e5e6",
   "metadata": {},
   "source": [
    "#### 分析\n",
    "\n",
    "可以看到，在Relu，Sigmoid和Tanh三种激活函数中，Relu激活函数在这一函数拟合任务上的表现最好，而其余两种激活函数的训练效率都要低很多。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd10454",
   "metadata": {},
   "source": [
    "## 实验代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909e35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x0000021242C6AD90>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ebc820",
   "metadata": {},
   "source": [
    "不同激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798f0b95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.9605 - accuracy: 0.7114 - val_loss: 0.6118 - val_accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.8948 - val_loss: 0.3030 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.9160 - val_loss: 0.2494 - val_accuracy: 0.9083\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9194 - val_loss: 0.2295 - val_accuracy: 0.9139\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9222 - val_loss: 0.2258 - val_accuracy: 0.9139\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9228 - val_loss: 0.2236 - val_accuracy: 0.9139\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9238 - val_loss: 0.2277 - val_accuracy: 0.9028\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9228 - val_loss: 0.2260 - val_accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9244 - val_loss: 0.2251 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.9231 - val_loss: 0.2277 - val_accuracy: 0.9056\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9300\n",
      "Test Accuracy (relu): 0.9300000071525574\n",
      "Final Training Accuracy (relu Neuron Configuration): 0.9231481552124023\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 1.3592 - accuracy: 0.3917 - val_loss: 1.2989 - val_accuracy: 0.5472\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1694 - accuracy: 0.6744 - val_loss: 1.0298 - val_accuracy: 0.6722\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.8056 - val_loss: 0.7929 - val_accuracy: 0.7917\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.8620 - val_loss: 0.6475 - val_accuracy: 0.8444\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.8935 - val_loss: 0.5337 - val_accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.9022 - val_loss: 0.4555 - val_accuracy: 0.8778\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.9133 - val_loss: 0.3916 - val_accuracy: 0.8917\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.9160 - val_loss: 0.3451 - val_accuracy: 0.9056\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.9185 - val_loss: 0.3137 - val_accuracy: 0.9056\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.9201 - val_loss: 0.2921 - val_accuracy: 0.9056\n",
      "13/13 [==============================] - 0s 980us/step - loss: 0.2813 - accuracy: 0.9300\n",
      "Test Accuracy (sigmoid): 0.9300000071525574\n",
      "Final Training Accuracy (sigmoid Neuron Configuration): 0.9200617074966431\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6982 - accuracy: 0.7864 - val_loss: 0.4745 - val_accuracy: 0.8528\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8907 - val_loss: 0.3253 - val_accuracy: 0.8972\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.9160 - val_loss: 0.2637 - val_accuracy: 0.9111\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.9188 - val_loss: 0.2490 - val_accuracy: 0.9056\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9225 - val_loss: 0.2410 - val_accuracy: 0.9111\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9235 - val_loss: 0.2386 - val_accuracy: 0.9139\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9228 - val_loss: 0.2276 - val_accuracy: 0.9139\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9253 - val_loss: 0.2291 - val_accuracy: 0.9083\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9235 - val_loss: 0.2297 - val_accuracy: 0.9194\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9244 - val_loss: 0.2231 - val_accuracy: 0.9167\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.2088 - accuracy: 0.9325\n",
      "Test Accuracy (tanh): 0.9325000047683716\n",
      "Final Training Accuracy (tanh Neuron Configuration): 0.9243826866149902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "dataset_path = \"dataset.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# 随机排序\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "features = data[['data1', 'data2']]\n",
    "labels = data['label']\n",
    "\n",
    "labels_onehot = pd.get_dummies(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_onehot, test_size=0.1, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "\n",
    "for activation_function in activation_functions:\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation=activation_function, input_shape=(2,)),\n",
    "        tf.keras.layers.Dense(32, activation=activation_function),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "    print(f'Test Accuracy ({activation_function}): {test_acc}')\n",
    "    final_train_accuracy = history.history['accuracy'][-1]\n",
    "    print(f'Final Training Accuracy ({activation_function} Neuron Configuration): {final_train_accuracy}')\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss with {activation_function.capitalize()}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy with {activation_function.capitalize()}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{activation_function}_training_plot.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5bfcc",
   "metadata": {},
   "source": [
    "不同隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b864fdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 1.0201 - accuracy: 0.6772 - val_loss: 0.7185 - val_accuracy: 0.7861\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.8404 - val_loss: 0.4029 - val_accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.9102 - val_loss: 0.2615 - val_accuracy: 0.9361\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.9182 - val_loss: 0.2081 - val_accuracy: 0.9556\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.9210 - val_loss: 0.1829 - val_accuracy: 0.9556\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9219 - val_loss: 0.1687 - val_accuracy: 0.9611\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9204 - val_loss: 0.1662 - val_accuracy: 0.9556\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9216 - val_loss: 0.1602 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9250 - val_loss: 0.1631 - val_accuracy: 0.9556\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9241 - val_loss: 0.1557 - val_accuracy: 0.9556\n",
      "13/13 [==============================] - 0s 961us/step - loss: 0.2356 - accuracy: 0.9150\n",
      "Test Accuracy ((32, 16) Neuron Configuration): 0.9150000214576721\n",
      "Final Training Accuracy ((32, 16) Neuron Configuration): 0.9240740537643433\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.8787 - accuracy: 0.6750 - val_loss: 0.4797 - val_accuracy: 0.8611\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.9028 - val_loss: 0.2152 - val_accuracy: 0.9472\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.9157 - val_loss: 0.1685 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9247 - val_loss: 0.1700 - val_accuracy: 0.9556\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9210 - val_loss: 0.1533 - val_accuracy: 0.9528\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.9216 - val_loss: 0.1615 - val_accuracy: 0.9528\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9201 - val_loss: 0.1639 - val_accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9231 - val_loss: 0.1710 - val_accuracy: 0.9417\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9228 - val_loss: 0.1511 - val_accuracy: 0.9556\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9228 - val_loss: 0.1505 - val_accuracy: 0.9556\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9175\n",
      "Test Accuracy ((64, 32, 16) Neuron Configuration): 0.9175000190734863\n",
      "Final Training Accuracy ((64, 32, 16) Neuron Configuration): 0.9228395223617554\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.7056 - accuracy: 0.8235 - val_loss: 0.2218 - val_accuracy: 0.9389\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9170 - val_loss: 0.1796 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9219 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9241 - val_loss: 0.1805 - val_accuracy: 0.9444\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9225 - val_loss: 0.1556 - val_accuracy: 0.9528\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9167 - val_loss: 0.1542 - val_accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9228 - val_loss: 0.1633 - val_accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9238 - val_loss: 0.2047 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9238 - val_loss: 0.1511 - val_accuracy: 0.9611\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9259 - val_loss: 0.1695 - val_accuracy: 0.9500\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.9075\n",
      "Test Accuracy ((128, 64, 32, 16) Neuron Configuration): 0.9075000286102295\n",
      "Final Training Accuracy ((128, 64, 32, 16) Neuron Configuration): 0.9259259104728699\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dataset_path = \"dataset.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# 随机排序\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "features = data[['data1', 'data2']]\n",
    "labels = data['label']\n",
    "\n",
    "labels_onehot = pd.get_dummies(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_onehot, test_size=0.1, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "neuron_configurations = [(32,16), (64,32,16), (128,64,32,16)]\n",
    "\n",
    "for configuration in neuron_configurations:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(configuration[0], activation='relu', input_shape=(2,)))\n",
    "\n",
    "    for neurons in configuration[1:]:\n",
    "        model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "    print(f'Test Accuracy ({configuration} Neuron Configuration): {test_acc}')\n",
    "    \n",
    "    final_train_accuracy = history.history['accuracy'][-1]\n",
    "    print(f'Final Training Accuracy ({configuration} Neuron Configuration): {final_train_accuracy}')\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss with {configuration}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Training and Validation Accuracy with {configuration}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{str(configuration)}_neuron_configuration_training_plot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c594e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
